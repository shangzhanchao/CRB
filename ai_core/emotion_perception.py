"""Emotion perception module.

æƒ…ç»ªè¯†åˆ«æ¨¡å—ï¼Œè´Ÿè´£ä»å¤šæ¨¡æ€è¾“å…¥ä¸­è¯†åˆ«ç”¨æˆ·æƒ…ç»ªã€‚
"""

import logging
from typing import Optional, Tuple

from .constants import LOG_LEVEL

logger = logging.getLogger(__name__)
logger.setLevel(LOG_LEVEL)


class EmotionPerception:
    """Emotion perception system.

    æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿï¼Œä»éŸ³é¢‘ã€å›¾åƒã€è§†é¢‘å’Œæ–‡æœ¬ä¸­è¯†åˆ«ç”¨æˆ·æƒ…ç»ªã€‚
    """

    def __init__(
        self,
        voiceprint_url: str | None = None,
        llm_url: str | None = None,
        memory=None,
        personality=None,
    ) -> None:
        """Initialize emotion perception system.

        åˆå§‹åŒ–æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿã€‚

        Parameters
        ----------
        voiceprint_url: str | None, optional
            Voiceprint service endpoint.
        llm_url: str | None, optional
            Large language model service endpoint.
        memory: optional
            Memory system for context.
        personality: optional
            Personality system for context.
        """
        self.voiceprint_url = voiceprint_url
        self.llm_url = llm_url
        self.memory = memory
        self.personality = personality
        
        logger.info(f"ğŸ”§ æƒ…ç»ªè¯†åˆ«ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   ğŸ¤ å£°çº¹æœåŠ¡: {voiceprint_url or 'æœªé…ç½®'}")
        logger.info(f"   ğŸ¤– LLMæœåŠ¡: {llm_url or 'æœªé…ç½®'}")

    def recognize_identity(self, audio_path: str) -> str:
        """Recognize user identity from audio.

        ä»éŸ³é¢‘ä¸­è¯†åˆ«ç”¨æˆ·èº«ä»½ã€‚

        Parameters
        ----------
        audio_path: str
            Path to audio file.

        Returns
        -------
        str
            User identifier.
        """
        # ç®€å•çš„èº«ä»½è¯†åˆ«å®ç°
        if self.voiceprint_url:
            try:
                from .service_api import call_voiceprint
                user_id = call_voiceprint(audio_path, self.voiceprint_url)
                logger.info(f"ğŸ¤ å£°çº¹è¯†åˆ«ç»“æœ: {user_id}")
                return user_id
            except Exception as e:
                logger.error(f"âŒ å£°çº¹è¯†åˆ«å¤±è´¥: {e}")
                return "unknown"
        else:
            return "unknown"

    def perceive_emotion(
        self, 
        audio_path: str, 
        image_or_video: str, 
        text: str
    ) -> Tuple[str, str]:
        """Perceive emotion from multimodal input.

        ä»å¤šæ¨¡æ€è¾“å…¥æ„ŸçŸ¥æƒ…ç»ªã€‚

        Parameters
        ----------
        audio_path: str
            Path to audio file.
        image_or_video: str
            Path to image or video file.
        text: str
            Text input.

        Returns
        -------
        Tuple[str, str]
            (mood_tag, user_id)
        """
        try:
            # è¯†åˆ«ç”¨æˆ·èº«ä»½
            user_id = self.recognize_identity(audio_path)
            
            # æ„ŸçŸ¥æƒ…ç»ª
            emotion_state = self.perceive(
                audio_path, image_or_video, text, user_id
            )
            
            # è·å–ä¸»å¯¼æƒ…ç»ª
            mood = emotion_state.overall(self.personality) if self.personality else "neutral"
            
            logger.info(f"ğŸ˜Š æƒ…ç»ªè¯†åˆ«ç»“æœ: {mood}, ç”¨æˆ·ID: {user_id}")
            return mood, user_id
            
        except Exception as e:
            logger.error(f"âŒ æƒ…ç»ªè¯†åˆ«å¤±è´¥: {e}")
            return "neutral", "unknown"

    def perceive(
        self,
        audio_path: str,
        image_or_video: str,
        text: str = "",
        user_id: str = "unknown",
    ) -> "EmotionState":
        """Perceive emotion from multimodal input.

        ä»å¤šæ¨¡æ€è¾“å…¥æ„ŸçŸ¥æƒ…ç»ªã€‚

        Parameters
        ----------
        audio_path: str
            Path to audio file.
        image_or_video: str
            Path to image or video file.
        text: str, optional
            Text input.
        user_id: str, optional
            User identifier.

        Returns
        -------
        EmotionState
            Emotion state object.
        """
        # åˆ›å»ºæƒ…ç»ªçŠ¶æ€å¯¹è±¡
        emotion_state = EmotionState()
        
        # ä»æ–‡æœ¬ä¸­è¯†åˆ«æƒ…ç»ª
        if text:
            emotion_state.text_emotion = self._analyze_text_emotion(text)
        
        # ä»éŸ³é¢‘ä¸­è¯†åˆ«æƒ…ç»ª
        if audio_path:
            emotion_state.audio_emotion = self._analyze_audio_emotion(audio_path)
        
        # ä»å›¾åƒ/è§†é¢‘ä¸­è¯†åˆ«æƒ…ç»ª
        if image_or_video:
            emotion_state.visual_emotion = self._analyze_visual_emotion(image_or_video)
        
        # ç»¼åˆæƒ…ç»ªåˆ†æ
        emotion_state.overall_emotion = self._combine_emotions(emotion_state)
        
        logger.info(f"ğŸ˜Š æƒ…ç»ªæ„ŸçŸ¥å®Œæˆ:")
        logger.info(f"   ğŸ“ æ–‡æœ¬æƒ…ç»ª: {emotion_state.text_emotion}")
        logger.info(f"   ğŸµ éŸ³é¢‘æƒ…ç»ª: {emotion_state.audio_emotion}")
        logger.info(f"   ğŸ–¼ï¸ è§†è§‰æƒ…ç»ª: {emotion_state.visual_emotion}")
        logger.info(f"   ğŸ¯ ç»¼åˆæƒ…ç»ª: {emotion_state.overall_emotion}")
        
        return emotion_state

    def _analyze_text_emotion(self, text: str) -> str:
        """Analyze emotion from text.

        ä»æ–‡æœ¬ä¸­åˆ†ææƒ…ç»ªã€‚

        Parameters
        ----------
        text: str
            Input text.

        Returns
        -------
        str
            Emotion tag.
        """
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        text_lower = text.lower()
        
        # ç§¯ææƒ…ç»ªå…³é”®è¯
        positive_keywords = ["å¼€å¿ƒ", "é«˜å…´", "å¿«ä¹", "å…´å¥‹", "æ„‰å¿«", "å¥½", "æ£’", "èµ", "å–œæ¬¢", "çˆ±"]
        for keyword in positive_keywords:
            if keyword in text_lower:
                return "happy"
        
        # æ¶ˆææƒ…ç»ªå…³é”®è¯
        negative_keywords = ["éš¾è¿‡", "ä¼¤å¿ƒ", "æ‚²ä¼¤", "æ²®ä¸§", "å¤±æœ›", "ä¸å¥½", "è®¨åŒ", "æ¨", "ç”Ÿæ°”", "æ„¤æ€’"]
        for keyword in negative_keywords:
            if keyword in text_lower:
                return "sad"
        
        # æƒŠè®¶æƒ…ç»ªå…³é”®è¯
        surprise_keywords = ["æƒŠè®¶", "éœ‡æƒŠ", "æ„å¤–", "åƒæƒŠ", "å“‡", "å“¦", "çœŸçš„å—"]
        for keyword in surprise_keywords:
            if keyword in text_lower:
                return "surprised"
        
        # æ„¤æ€’æƒ…ç»ªå…³é”®è¯
        anger_keywords = ["ç”Ÿæ°”", "æ„¤æ€’", "æ¼ç«", "çƒ¦èº", "è®¨åŒ", "æ¨"]
        for keyword in anger_keywords:
            if keyword in text_lower:
                return "angry"
        
        # å…´å¥‹æƒ…ç»ªå…³é”®è¯
        excited_keywords = ["æ¿€åŠ¨", "å…´å¥‹", "çƒ­æƒ…", "æŒ¯å¥‹", "å¤ªæ£’äº†", "å¤ªå¥½äº†"]
        for keyword in excited_keywords:
            if keyword in text_lower:
                return "excited"
        
        return "neutral"

    def _analyze_audio_emotion(self, audio_path: str) -> str:
        """Analyze emotion from audio.

        ä»éŸ³é¢‘ä¸­åˆ†ææƒ…ç»ªã€‚

        Parameters
        ----------
        audio_path: str
            Path to audio file.

        Returns
        -------
        str
            Emotion tag.
        """
        # ç®€å•çš„éŸ³é¢‘æƒ…ç»ªåˆ†æ
        # è¿™é‡Œå¯ä»¥é›†æˆæ›´å¤æ‚çš„éŸ³é¢‘åˆ†æåº“
        try:
            # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            import os
            if os.path.exists(audio_path):
                # åŸºäºæ–‡ä»¶å¤§å°çš„ç®€å•åˆ¤æ–­
                file_size = os.path.getsize(audio_path)
                if file_size > 10000:  # å¤§äº10KBçš„éŸ³é¢‘å¯èƒ½åŒ…å«æ›´å¤šä¿¡æ¯
                    return "excited"
                else:
                    return "neutral"
            else:
                return "neutral"
        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return "neutral"

    def _analyze_visual_emotion(self, image_or_video: str) -> str:
        """Analyze emotion from visual input.

        ä»è§†è§‰è¾“å…¥ä¸­åˆ†ææƒ…ç»ªã€‚

        Parameters
        ----------
        image_or_video: str
            Path to image or video file.

        Returns
        -------
        str
            Emotion tag.
        """
        # ç®€å•çš„è§†è§‰æƒ…ç»ªåˆ†æ
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            import os
            if os.path.exists(image_or_video):
                # åŸºäºæ–‡ä»¶æ‰©å±•åçš„ç®€å•åˆ¤æ–­
                file_ext = os.path.splitext(image_or_video)[1].lower()
                if file_ext in ['.jpg', '.jpeg', '.png', '.gif']:
                    return "happy"  # å›¾ç‰‡é€šå¸¸è¡¨ç¤ºç§¯ææƒ…ç»ª
                elif file_ext in ['.mp4', '.avi', '.mov', '.webm']:
                    return "excited"  # è§†é¢‘é€šå¸¸è¡¨ç¤ºå…´å¥‹æƒ…ç»ª
                else:
                    return "neutral"
            else:
                return "neutral"
        except Exception as e:
            logger.error(f"âŒ è§†è§‰æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return "neutral"

    def _combine_emotions(self, emotion_state: "EmotionState") -> str:
        """Combine emotions from different modalities.

        èåˆä¸åŒæ¨¡æ€çš„æƒ…ç»ªã€‚

        Parameters
        ----------
        emotion_state: EmotionState
            Emotion state object.

        Returns
        -------
        str
            Combined emotion tag.
        """
        emotions = []
        
        if emotion_state.text_emotion != "neutral":
            emotions.append(emotion_state.text_emotion)
        
        if emotion_state.audio_emotion != "neutral":
            emotions.append(emotion_state.audio_emotion)
        
        if emotion_state.visual_emotion != "neutral":
            emotions.append(emotion_state.visual_emotion)
        
        if not emotions:
            return "neutral"
        
        # ç®€å•çš„æƒ…ç»ªèåˆç­–ç•¥
        # å¦‚æœæœ‰å¤šä¸ªæƒ…ç»ªï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªéä¸­æ€§æƒ…ç»ª
        return emotions[0]


class EmotionState:
    """Emotion state container.

    æƒ…ç»ªçŠ¶æ€å®¹å™¨ã€‚
    """

    def __init__(self):
        """Initialize emotion state."""
        self.text_emotion = "neutral"
        self.audio_emotion = "neutral"
        self.visual_emotion = "neutral"
        self.overall_emotion = "neutral"

    def overall(self, personality=None) -> str:
        """Get overall emotion considering personality.

        è€ƒè™‘äººæ ¼å› ç´ çš„ç»¼åˆæƒ…ç»ªã€‚

        Parameters
        ----------
        personality: optional
            Personality system.

        Returns
        -------
        str
            Overall emotion tag.
        """
        # å¦‚æœæœ‰æƒ…ç»ªè¯†åˆ«ç»“æœï¼Œä½¿ç”¨å®ƒ
        if self.overall_emotion != "neutral":
            return self.overall_emotion
        
        # å¦åˆ™ä½¿ç”¨æ–‡æœ¬æƒ…ç»ª
        return self.text_emotion