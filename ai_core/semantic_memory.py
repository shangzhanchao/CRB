"""Semantic episodic memory module backed by SQLite.

æ–‡ä»¶ç»“æ„è¯´æ˜ï¼š

```
SemanticMemory -> æ ¸å¿ƒç±»
  _embed()     -> æ–‡æœ¬æˆ–å¥å‘é‡åµŒå…¥å‡½æ•°
  add_memory() -> å­˜å…¥å¯¹è¯è®°å½•å¹¶æ›´æ–°ç´¢å¼•
  query_memory() -> ä½¿ç”¨å‘é‡æœç´¢ç›¸ä¼¼å†…å®¹
```
"""

import datetime
import hashlib
import logging
import json
import os
import sqlite3
from typing import List, Dict, Any

try:
    import numpy as np  # type: ignore
except ImportError:  # pragma: no cover
    np = None


from .constants import (
    LOG_LEVEL,
    DEFAULT_MEMORY_SAVE_URL,
    DEFAULT_MEMORY_QUERY_URL,
    MEMORY_DB_PATH,
)
from .service_api import call_memory_save, call_memory_query

try:
    from sentence_transformers import SentenceTransformer  # type: ignore
except Exception:  # pragma: no cover - library missing
    SentenceTransformer = None

logger = logging.getLogger(__name__)
logger.setLevel(LOG_LEVEL)


class SemanticMemory:
    """Simple vector-based semantic memory using SQLite.

    åŸºäºå‘é‡çš„è¯­ä¹‰è®°å¿†æ¨¡å—ï¼Œä½¿ç”¨ SQLite æ•°æ®åº“å­˜å‚¨è®°å½•ã€‚
    """

    def __init__(
        self,
        vector_dim: int = 384,
        save_url: str | None = DEFAULT_MEMORY_SAVE_URL,
        query_url: str | None = DEFAULT_MEMORY_QUERY_URL,
        use_transformer: bool | None = None,
        model_name: str = "all-MiniLM-L6-v2",
        db_path: str = MEMORY_DB_PATH,
    ) -> None:
        """Initialize memory store backed by SQLite.

        åˆå§‹åŒ–åŸºäº SQLite çš„è®°å¿†å­˜å‚¨ã€‚

        Parameters
        ----------
        vector_dim: int, optional
            Dimensionality of embedding vectors. åµŒå…¥å‘é‡çš„ç»´åº¦ï¼Œé»˜è®¤ä¸º ``384``ã€‚
        save_url: str | None, optional
            Remote service to store memory records. è®°å¿†å­˜å‚¨æœåŠ¡åœ°å€ã€‚
        query_url: str | None, optional
            Remote service to query memory records. è®°å¿†æŸ¥è¯¢æœåŠ¡åœ°å€ã€‚
        db_path: str, optional
            Path to the SQLite database storing memory records.
            è®°å¿†è®°å½•ä¿å­˜çš„ SQLite æ•°æ®åº“è·¯å¾„ã€‚
        """
        self.vector_dim = vector_dim  # å‘é‡ç»´åº¦
        self.records: List[Dict[str, Any]] = []  # å­˜å‚¨å¯¹è¯è®°å½•
        self.save_url = save_url
        self.query_url = query_url
        self.transformer = None
        if use_transformer is None:
            use_transformer = SentenceTransformer is not None
        if use_transformer and SentenceTransformer is not None:
            try:
                self.transformer = SentenceTransformer(model_name)
                test_vec = self.transformer.encode(["test"])[0]
                self.vector_dim = len(test_vec)
            except Exception as exc:  # pragma: no cover
                logger.warning("SentenceTransformer load failed: %s", exc)
                self.transformer = None
        self.db_path = db_path
        self.conn = sqlite3.connect(self.db_path)
        self.conn.row_factory = sqlite3.Row
        self._init_db()
        self.load()

    def _init_db(self) -> None:
        """Create the memory table if it doesn't exist."""
        cur = self.conn.cursor()
        cur.execute(
            """
            CREATE TABLE IF NOT EXISTS memory (
                time TEXT,
                user_text TEXT,
                ai_response TEXT,
                mood_tag TEXT,
                user_id TEXT,
                touched INTEGER,
                touch_zone INTEGER,
                vector TEXT
            )
            """
        )
        self.conn.commit()

    def load(self) -> None:
        """Load records from the SQLite database into memory."""
        cur = self.conn.cursor()
        rows = cur.execute("SELECT * FROM memory").fetchall()
        self.records = []
        for row in rows:
            self.records.append(
                {
                    "time": datetime.datetime.fromisoformat(row["time"]),
                    "user_text": row["user_text"],
                    "ai_response": row["ai_response"],
                    "mood_tag": row["mood_tag"],
                    "user_id": row["user_id"],
                    "touched": bool(row["touched"]),
                    "touch_zone": row["touch_zone"],
                    "topic_vector": json.loads(row["vector"]),
                }
            )

    def _embed(self, text: str):
        """Convert text to a vector using sentence transformers when available.

        ä¼˜å…ˆä½¿ç”¨ ``sentence-transformers`` ç”ŸæˆçœŸå®è¯­ä¹‰å‘é‡ï¼Œè‹¥åº“æˆ–æ¨¡å‹ç¼ºå¤±
        åˆ™é€€åŒ–ä¸ºæ”¹è¿›çš„å“ˆå¸Œå‘é‡ã€‚"""

        logger.debug("Embedding text: %s", text)
        if self.transformer is not None:
            try:
                vec = self.transformer.encode([text])[0]
                if np is not None:
                    return np.array(vec, dtype="float32")
                return [float(v) for v in vec]
            except Exception as exc:  # pragma: no cover
                logger.warning("Transformer embedding failed: %s", exc)

        # æ”¹è¿›çš„å“ˆå¸Œå‘é‡ç”Ÿæˆ
        # 1. åˆ†è¯å¤„ç†
        words = text.lower().split()
        # 2. ç”Ÿæˆè¯çº§åˆ«çš„å“ˆå¸Œ
        word_hashes = []
        for word in words:
            word_hash = hashlib.md5(word.encode("utf-8")).digest()
            word_hashes.extend([b / 255.0 for b in word_hash[:8]])
        
        # 3. ç”Ÿæˆå¥å­çº§åˆ«çš„å“ˆå¸Œ
        sentence_hash = hashlib.sha256(text.encode("utf-8")).digest()
        sentence_vec = [b / 255.0 for b in sentence_hash[:16]]
        
        # 4. ç»„åˆå‘é‡
        combined_vec = word_hashes + sentence_vec
        
        # 5. è°ƒæ•´åˆ°ç›®æ ‡ç»´åº¦
        if len(combined_vec) < self.vector_dim:
            combined_vec += [0.0] * (self.vector_dim - len(combined_vec))
        else:
            combined_vec = combined_vec[:self.vector_dim]
        
        return combined_vec


    def add_memory(
        self,
        user_text: str,
        ai_response: str,
        mood_tag: str = "neutral",
        user_id: str = "unknown",
        touched: bool = False,
        touch_zone: int | None = None,
    ) -> None:
        """Add a conversation record into memory.

        æ–°å¢ä¸€æ¡å¯¹è¯è®°å½•åˆ°è®°å¿†åº“ä¸­ã€‚

        Parameters
        ----------
        user_text: str
            User input text.
        ai_response: str
            Reply generated by the system.
        mood_tag: str, optional
            Emotion label associated with the conversation. Defaults to
            ``"neutral"`` when unspecified.
            å¯¹åº”çš„æƒ…ç»ªæ ‡ç­¾ï¼Œé»˜è®¤å€¼ä¸º ``"neutral"``ã€‚
        touch_zone: int | None, optional
            Identifier for the touch sensor zone if a touch interaction
            occurred.  è§¦æ‘¸ä¼ æ„Ÿå™¨çš„åŒºåŸŸç¼–å·ï¼Œå¯ä¸º ``None`` è¡¨ç¤ºæ— è§¦æ‘¸ã€‚"""
        vec = self._embed(user_text)
        record = {
            "time": datetime.datetime.utcnow(),
            "user_text": user_text,
            "ai_response": ai_response,
            "mood_tag": mood_tag,
            "user_id": user_id,
            "touched": touched,
            "touch_zone": touch_zone,
            "topic_vector": vec,
        }
        self.records.append(record)
        
        # å¢å¼ºè®°å¿†æ—¥å¿—è¾“å‡º
        logger.info("ğŸ’¾ æ–°å¢è®°å¿†è®°å½•")
        logger.info(f"   ğŸ“ ç”¨æˆ·è¾“å…¥: {user_text}")
        logger.info(f"   ğŸ¤– AIå›å¤: {ai_response}")
        logger.info(f"   ğŸ˜Š æƒ…ç»ªæ ‡ç­¾: {mood_tag}")
        logger.info(f"   ğŸ‘¤ ç”¨æˆ·ID: {user_id}")
        logger.info(f"   ğŸ¤— è§¦æ‘¸çŠ¶æ€: {touched}")
        logger.info(f"   ğŸ“ è§¦æ‘¸åŒºåŸŸ: {touch_zone}")
        logger.info(f"   ğŸ“Š è®°å¿†æ€»æ•°: {len(self.records)}")
        
        cur = self.conn.cursor()
        cur.execute(
            "INSERT INTO memory VALUES (?,?,?,?,?,?,?,?)",
            (
                record["time"].isoformat(),
                user_text,
                ai_response,
                mood_tag,
                user_id,
                int(touched),
                touch_zone,
                json.dumps(vec),
            ),
        )
        self.conn.commit()
        if self.save_url:
            ok = call_memory_save(record, self.save_url)
            if not ok:
                logger.info(
                    "Remote memory service failed; record kept locally.")
        
    def query_memory(
        self, prompt: str, top_k: int = 3, user_id: str | None = None
    ) -> List[Dict[str, Any]]:
        """Return most relevant past interactions for the prompt.

        æ ¹æ®æç¤ºæŸ¥è¯¢æœ€ç›¸å…³çš„å†å²å¯¹è¯ã€‚

        Parameters
        ----------
        prompt: str
            Query text used for retrieving memories.
        top_k: int, optional
            Number of records to return. é»˜è®¤è¿”å› 3 æ¡è®°å½•ã€‚
        user_id: str | None, optional
            If provided, filter memories belonging to this user.
            å¦‚æä¾›è¯¥å‚æ•°ï¼Œåˆ™åªè¿”å›è¯¥ç”¨æˆ·çš„å†å²è®°å½•ã€‚
        """
        query_vec = self._embed(prompt)
        logger.debug("Querying memory for: %s", prompt)
        if self.query_url:
            res = call_memory_query(prompt, top_k, self.query_url)
            if res is not None:
                return res
        candidates = [
            r for r in self.records if user_id is None or r.get("user_id") == user_id
        ]
        # æ”¹è¿›çš„ç›¸ä¼¼åº¦æœç´¢
        def similarity(a, b):
            """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
            dot_product = sum(x * y for x, y in zip(a, b))
            norm_a = sum(x * x for x in a) ** 0.5
            norm_b = sum(x * x for x in b) ** 0.5
            if norm_a == 0 or norm_b == 0:
                return 0
            return dot_product / (norm_a * norm_b)
        
        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        scores = [similarity(r["topic_vector"], query_vec) for r in candidates]
        # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åºï¼ˆç›¸ä¼¼åº¦è¶Šé«˜è¶Šå¥½ï¼‰
        top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]
        results = [candidates[i] for i in top_indices]
        
        # å¢å¼ºè®°å¿†æŸ¥è¯¢æ—¥å¿—è¾“å‡º
        logger.info("ğŸ” è®°å¿†æŸ¥è¯¢ç»“æœ")
        logger.info(f"   ğŸ“ æŸ¥è¯¢å†…å®¹: {prompt}")
        logger.info(f"   ğŸ“Š å€™é€‰è®°å½•æ•°: {len(candidates)}")
        logger.info(f"   ğŸ¯ è¿”å›è®°å½•æ•°: {len(results)}")
        if results:
            logger.info("   ğŸ“‹ ç›¸å…³è®°å¿†:")
            for i, result in enumerate(results, 1):
                logger.info(f"     {i}. ç”¨æˆ·: {result['user_text']}")
                logger.info(f"        AI: {result['ai_response']}")
                logger.info(f"        æƒ…ç»ª: {result['mood_tag']}")
                logger.info(f"        æ—¶é—´: {result['time']}")
        
        return results  # è¿”å›æŒ‰è·ç¦»æ’åºçš„ç»“æœ

    def save_backup(self, path: str) -> None:
        """Save memory records to a JSON backup file.

        å°†è®°å¿†è®°å½•ä¿å­˜åˆ° JSON å¤‡ä»½æ–‡ä»¶ã€‚
        """
        with open(path, "w", encoding="utf-8") as fh:
            json.dump(self.records, fh, default=str, ensure_ascii=False)
        logger.info("Memory backup saved to %s", path)

    def load_backup(self, path: str) -> None:
        """Load memory records from a JSON backup file."""
        try:
            with open(path, "r", encoding="utf-8") as fh:
                self.records = json.load(fh)
        except FileNotFoundError:
            logger.warning("Memory file %s not found", path)
            self.records = []
        logger.info("Loaded %d memory records from backup", len(self.records))

    def last_mood(self, user_id: str | None = None) -> str | None:
        """Return the most recent mood tag for a user."""

        # è¿”å›ç»™å®šç”¨æˆ·æœ€è¿‘ä¸€æ¬¡å¯¹è¯çš„æƒ…ç»ªæ ‡ç­¾
        candidates = [r for r in self.records if user_id is None or r.get("user_id") == user_id]
        if not candidates:
            return None
        return candidates[-1].get("mood_tag")