"""Hybrid memory system combining session memory and semantic memory.

èåˆè®°å¿†ç³»ç»Ÿï¼Œç»“åˆä¼šè¯è®°å½•å’Œè¯­ä¹‰è®°å¿†ï¼Œæä¾›æ›´æ™ºèƒ½çš„è®°å¿†ç®¡ç†ã€‚
"""

import datetime
import logging
import json
from dataclasses import dataclass, asdict
from typing import List, Dict, Any, Optional, Tuple
from collections import deque

from .semantic_memory import SemanticMemory
from .constants import (
    SESSION_MEMORY_LIMIT,
    MEMORY_FUSION_THRESHOLD,
    CONTEXT_WINDOW_SIZE,
    ROBOT_MEMORY_PREFIX,
    MEMORY_CONFIG,
    LOG_LEVEL,
)

logger = logging.getLogger(__name__)
logger.setLevel(LOG_LEVEL)


@dataclass
class SessionRecord:
    """ä¼šè¯è®°å½•æ•°æ®ç»“æ„"""
    robot_id: str                    # æœºå™¨äººç¼–å·
    timestamp: datetime.datetime      # æ—¶é—´æˆ³
    user_text: str                   # ç”¨æˆ·è¾“å…¥
    ai_response: str                 # AIå›å¤
    mood_tag: str                    # æƒ…ç»ªæ ‡ç­¾
    touch_zone: Optional[int]        # è§¦æ‘¸åŒºåŸŸ
    context_id: str                  # ä¸Šä¸‹æ–‡ID
    importance_score: float           # é‡è¦æ€§è¯„åˆ†


@dataclass
class SemanticRecord:
    """è¯­ä¹‰è®°å¿†æ•°æ®ç»“æ„"""
    robot_id: str                    # æœºå™¨äººç¼–å·
    timestamp: datetime.datetime      # æ—¶é—´æˆ³
    content: str                     # è®°å¿†å†…å®¹
    vector: List[float]              # è¯­ä¹‰å‘é‡
    mood_tag: str                    # æƒ…ç»ªæ ‡ç­¾
    touch_zone: Optional[int]        # è§¦æ‘¸åŒºåŸŸ
    importance_score: float           # é‡è¦æ€§è¯„åˆ†
    memory_type: str                 # è®°å¿†ç±»å‹


class HybridMemoryManager:
    """èåˆè®°å¿†ç®¡ç†å™¨
    
    ç»“åˆä¼šè¯è®°å½•ï¼ˆçŸ­æœŸè®°å¿†ï¼‰å’Œè¯­ä¹‰è®°å¿†ï¼ˆé•¿æœŸè®°å¿†ï¼‰çš„æ™ºèƒ½è®°å¿†ç³»ç»Ÿã€‚
    """

    def __init__(
        self,
        robot_id: str,
        session_limit: int = SESSION_MEMORY_LIMIT,
        semantic_memory: Optional[SemanticMemory] = None,
    ):
        """åˆå§‹åŒ–èåˆè®°å¿†ç®¡ç†å™¨
        
        Parameters
        ----------
        robot_id: str
            æœºå™¨äººç¼–å·
        session_limit: int, optional
            ä¼šè¯è®°å½•æœ€å¤§æ¡æ•°ï¼Œé»˜è®¤ä¸º SESSION_MEMORY_LIMIT
        semantic_memory: SemanticMemory, optional
            è¯­ä¹‰è®°å¿†å®ä¾‹ï¼Œå¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°çš„å®ä¾‹
        """
        self.robot_id = robot_id
        self.session_limit = session_limit
        self.session_memory = deque(maxlen=session_limit)  # ä½¿ç”¨dequeå®ç°FIFO
        self.semantic_memory = semantic_memory or SemanticMemory()
        self.context_counter = 0
        
        logger.info(f"ğŸ”§ åˆå§‹åŒ–èåˆè®°å¿†ç®¡ç†å™¨ - æœºå™¨äººID: {robot_id}")
        logger.info(f"   ğŸ“Š ä¼šè¯è®°å½•é™åˆ¶: {session_limit}")
        logger.info(f"   ğŸ§  è¯­ä¹‰è®°å¿†çŠ¶æ€: {'å·²è¿æ¥' if semantic_memory else 'æ–°å»º'}")
    
    def add_memory(
        self,
        user_text: str,
        ai_response: str,
        mood_tag: str = "neutral",
        user_id: str = "unknown",
        touched: bool = False,
        touch_zone: Optional[int] = None,
    ) -> None:
        """æ·»åŠ è®°å¿†åˆ°ä¸¤ä¸ªå±‚æ¬¡
        
        Parameters
        ----------
        user_text: str
            ç”¨æˆ·è¾“å…¥æ–‡æœ¬
        ai_response: str
            AIå›å¤æ–‡æœ¬
        mood_tag: str, optional
            æƒ…ç»ªæ ‡ç­¾ï¼Œé»˜è®¤ä¸º "neutral"
        user_id: str, optional
            ç”¨æˆ·IDï¼Œé»˜è®¤ä¸º "unknown"
        touched: bool, optional
            æ˜¯å¦è¢«è§¦æ‘¸ï¼Œé»˜è®¤ä¸º False
        touch_zone: int | None, optional
            è§¦æ‘¸åŒºåŸŸï¼Œé»˜è®¤ä¸º None
        """
        # ç”Ÿæˆä¸Šä¸‹æ–‡ID
        self.context_counter += 1
        context_id = f"{self.robot_id}_ctx_{self.context_counter}"
        
        # è®¡ç®—é‡è¦æ€§è¯„åˆ†
        importance_score = self._calculate_importance_score(
            user_text, ai_response, mood_tag, touched
        )
        
        # 1. æ·»åŠ åˆ°ä¼šè¯è®°å½•
        session_record = SessionRecord(
            robot_id=self.robot_id,
            timestamp=datetime.datetime.utcnow(),
            user_text=user_text,
            ai_response=ai_response,
            mood_tag=mood_tag,
            touch_zone=touch_zone,
            context_id=context_id,
            importance_score=importance_score,
        )
        
        self.session_memory.append(session_record)
        
        # 2. æ·»åŠ åˆ°è¯­ä¹‰è®°å¿†
        self.semantic_memory.add_memory(
            user_text=user_text,
            ai_response=ai_response,
            mood_tag=mood_tag,
            user_id=user_id,
            touched=touched,
            touch_zone=touch_zone,
        )
        
        logger.info(f"ğŸ’¾ è®°å¿†å·²æ·»åŠ  - ä¸Šä¸‹æ–‡ID: {context_id}")
        logger.info(f"   ğŸ“ ç”¨æˆ·: {user_text}")
        logger.info(f"   ğŸ¤– AI: {ai_response}")
        logger.info(f"   ğŸ˜Š æƒ…ç»ª: {mood_tag}")
        logger.info(f"   ğŸ“Š é‡è¦æ€§: {importance_score:.3f}")
        logger.info(f"   ğŸ“ˆ ä¼šè¯è®°å½•æ•°: {len(self.session_memory)}")
    
    def query_memory(
        self,
        prompt: str,
        top_k: int = 5,
        user_id: Optional[str] = None,
        use_fusion: bool = True,
    ) -> Dict[str, Any]:
        """èåˆæŸ¥è¯¢ä¸¤ä¸ªå±‚æ¬¡çš„è®°å¿†
        
        Parameters
        ----------
        prompt: str
            æŸ¥è¯¢æç¤º
        top_k: int, optional
            è¿”å›è®°å½•æ•°é‡ï¼Œé»˜è®¤ä¸º 5
        user_id: str | None, optional
            ç”¨æˆ·IDè¿‡æ»¤ï¼Œé»˜è®¤ä¸º None
        use_fusion: bool, optional
            æ˜¯å¦ä½¿ç”¨èåˆæŸ¥è¯¢ï¼Œé»˜è®¤ä¸º True
        
        Returns
        -------
        Dict[str, Any]
            åŒ…å«è®°å¿†æŸ¥è¯¢ç»“æœçš„å­—å…¸
        """
        logger.info(f"ğŸ” å¼€å§‹è®°å¿†æŸ¥è¯¢ - æç¤º: {prompt}")
        
        # 1. æŸ¥è¯¢ä¼šè¯è®°å½•
        session_results = self._query_session_memory(prompt, top_k)
        
        # 2. æŸ¥è¯¢è¯­ä¹‰è®°å¿†
        semantic_results = self.semantic_memory.query_memory(
            prompt, top_k=top_k, user_id=user_id
        )
        
        # 3. èåˆç»“æœ
        if use_fusion and session_results and semantic_results:
            fused_results = self._fuse_memories(
                session_results, semantic_results, top_k
            )
            memory_type = "fused"
        else:
            # ä¼˜å…ˆä½¿ç”¨ä¼šè¯è®°å½•ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨è¯­ä¹‰è®°å¿†
            if session_results:
                fused_results = session_results
                memory_type = "session"
            else:
                fused_results = semantic_results
                memory_type = "semantic"
        
        # 4. ç”Ÿæˆè®°å¿†æ‘˜è¦
        memory_summary = self._generate_memory_summary(fused_results)
        
        result = {
            "memory_type": memory_type,
            "records": fused_results,
            "summary": memory_summary,
            "session_count": len(session_results),
            "semantic_count": len(semantic_results),
            "total_count": len(fused_results),
        }
        
        logger.info(f"ğŸ“‹ è®°å¿†æŸ¥è¯¢å®Œæˆ")
        logger.info(f"   ğŸ¯ è®°å¿†ç±»å‹: {memory_type}")
        logger.info(f"   ğŸ“Š ä¼šè¯è®°å½•: {len(session_results)}")
        logger.info(f"   ğŸ§  è¯­ä¹‰è®°å¿†: {len(semantic_results)}")
        logger.info(f"   ğŸ“ æ€»è®°å½•æ•°: {len(fused_results)}")
        
        return result
    
    def get_context_memory(
        self, window_size: int = CONTEXT_WINDOW_SIZE
    ) -> List[SessionRecord]:
        """è·å–æœ€è¿‘çš„ä¸Šä¸‹æ–‡è®°å¿†
        
        Parameters
        ----------
        window_size: int, optional
            ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼Œé»˜è®¤ä¸º CONTEXT_WINDOW_SIZE
        
        Returns
        -------
        List[SessionRecord]
            æœ€è¿‘çš„ä¼šè¯è®°å½•åˆ—è¡¨
        """
        if not self.session_memory:
            return []
        
        # è·å–æœ€è¿‘çš„è®°å½•
        recent_records = list(self.session_memory)[-window_size:]
        
        logger.info(f"ğŸ“– è·å–ä¸Šä¸‹æ–‡è®°å¿† - çª—å£å¤§å°: {window_size}")
        logger.info(f"   ğŸ“Š è¿”å›è®°å½•æ•°: {len(recent_records)}")
        
        return recent_records
    
    def archive_important_memories(self, importance_threshold: float = 0.8) -> int:
        """å°†é‡è¦è®°å¿†å½’æ¡£åˆ°è¯­ä¹‰è®°å¿†
        
        Parameters
        ----------
        importance_threshold: float, optional
            é‡è¦æ€§é˜ˆå€¼ï¼Œé»˜è®¤ä¸º 0.8
        
        Returns
        -------
        int
            å½’æ¡£çš„è®°å¿†æ•°é‡
        """
        if not self.session_memory:
            return 0
        
        archived_count = 0
        records_to_remove = []
        
        for record in self.session_memory:
            if record.importance_score >= importance_threshold:
                # å°†é‡è¦è®°å¿†è½¬æ¢ä¸ºè¯­ä¹‰è®°å¿†æ ¼å¼
                semantic_record = SemanticRecord(
                    robot_id=record.robot_id,
                    timestamp=record.timestamp,
                    content=f"ç”¨æˆ·: {record.user_text} | AI: {record.ai_response}",
                    vector=self.semantic_memory._embed(record.user_text),
                    mood_tag=record.mood_tag,
                    touch_zone=record.touch_zone,
                    importance_score=record.importance_score,
                    memory_type="archived_session",
                )
                
                # æ·»åŠ åˆ°è¯­ä¹‰è®°å¿†ï¼ˆè¿™é‡Œéœ€è¦æ‰©å±•è¯­ä¹‰è®°å¿†çš„æ¥å£ï¼‰
                records_to_remove.append(record)
                archived_count += 1
        
        # ä»ä¼šè¯è®°å¿†ä¸­ç§»é™¤å·²å½’æ¡£çš„è®°å½•
        for record in records_to_remove:
            try:
                self.session_memory.remove(record)
            except ValueError:
                pass  # è®°å½•å¯èƒ½å·²ç»è¢«ç§»é™¤
        
        logger.info(f"ğŸ“¦ è®°å¿†å½’æ¡£å®Œæˆ")
        logger.info(f"   ğŸ“Š å½’æ¡£æ•°é‡: {archived_count}")
        logger.info(f"   ğŸ“ˆ å‰©ä½™ä¼šè¯è®°å½•: {len(self.session_memory)}")
        
        return archived_count
    
    def _query_session_memory(
        self, prompt: str, top_k: int
    ) -> List[Dict[str, Any]]:
        """æŸ¥è¯¢ä¼šè¯è®°å¿†
        
        Parameters
        ----------
        prompt: str
            æŸ¥è¯¢æç¤º
        top_k: int
            è¿”å›è®°å½•æ•°é‡
        
        Returns
        -------
        List[Dict[str, Any]]
            ä¼šè¯è®°å¿†è®°å½•åˆ—è¡¨
        """
        if not self.session_memory:
            return []
        
        # ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼ˆå¯ä»¥åç»­ä¼˜åŒ–ä¸ºå‘é‡æœç´¢ï¼‰
        prompt_lower = prompt.lower()
        matched_records = []
        
        for record in self.session_memory:
            # æ£€æŸ¥ç”¨æˆ·è¾“å…¥å’ŒAIå›å¤ä¸­æ˜¯å¦åŒ…å«å…³é”®è¯
            user_match = any(word in record.user_text.lower() 
                           for word in prompt_lower.split())
            ai_match = any(word in record.ai_response.lower() 
                          for word in prompt_lower.split())
            
            if user_match or ai_match:
                matched_records.append({
                    "time": record.timestamp,
                    "user_text": record.user_text,
                    "ai_response": record.ai_response,
                    "mood_tag": record.mood_tag,
                    "user_id": self.robot_id,
                    "touched": False,  # ä¼šè¯è®°å½•ä¸­ä¸ç›´æ¥å­˜å‚¨è§¦æ‘¸çŠ¶æ€
                    "touch_zone": record.touch_zone,
                    "topic_vector": [],  # ä¼šè¯è®°å½•ä¸å­˜å‚¨å‘é‡
                    "importance_score": record.importance_score,
                    "memory_type": "session",
                })
        
        # æŒ‰é‡è¦æ€§è¯„åˆ†å’Œæ—¶é—´æ’åº
        matched_records.sort(
            key=lambda x: (x["importance_score"], x["time"]), 
            reverse=True
        )
        
        return matched_records[:top_k]
    
    def _fuse_memories(
        self,
        session_memories: List[Dict[str, Any]],
        semantic_memories: List[Dict[str, Any]],
        top_k: int,
    ) -> List[Dict[str, Any]]:
        """èåˆä¼šè¯è®°å¿†å’Œè¯­ä¹‰è®°å¿†
        
        Parameters
        ----------
        session_memories: List[Dict[str, Any]]
            ä¼šè¯è®°å¿†åˆ—è¡¨
        semantic_memories: List[Dict[str, Any]]
            è¯­ä¹‰è®°å¿†åˆ—è¡¨
        top_k: int
            è¿”å›è®°å½•æ•°é‡
        
        Returns
        -------
        List[Dict[str, Any]]
            èåˆåçš„è®°å¿†åˆ—è¡¨
        """
        # åˆå¹¶æ‰€æœ‰è®°å¿†
        all_memories = session_memories + semantic_memories
        
        # å»é‡å¤„ç†ï¼ˆåŸºäºå†…å®¹å’Œæ—¶é—´ï¼‰
        unique_memories = []
        seen_contents = set()
        
        for memory in all_memories:
            content_key = f"{memory['user_text']}_{memory['ai_response']}"
            if content_key not in seen_contents:
                seen_contents.add(content_key)
                unique_memories.append(memory)
        
        # æŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        unique_memories.sort(key=lambda x: x["time"], reverse=True)
        
        # è®¡ç®—ç›¸ä¼¼åº¦å¹¶å»é‡
        final_memories = []
        for memory in unique_memories:
            is_similar = False
            for existing in final_memories:
                similarity = self._calculate_similarity(memory, existing)
                if similarity > MEMORY_FUSION_THRESHOLD:
                    is_similar = True
                    break
            
            if not is_similar:
                final_memories.append(memory)
                if len(final_memories) >= top_k:
                    break
        
        return final_memories
    
    def _calculate_similarity(
        self, memory1: Dict[str, Any], memory2: Dict[str, Any]
    ) -> float:
        """è®¡ç®—ä¸¤ä¸ªè®°å¿†çš„ç›¸ä¼¼åº¦
        
        Parameters
        ----------
        memory1: Dict[str, Any]
            ç¬¬ä¸€ä¸ªè®°å¿†
        memory2: Dict[str, Any]
            ç¬¬äºŒä¸ªè®°å¿†
        
        Returns
        -------
        float
            ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
        """
        # ç®€å•çš„æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—
        text1 = f"{memory1['user_text']} {memory1['ai_response']}".lower()
        text2 = f"{memory2['user_text']} {memory2['ai_response']}".lower()
        
        # è®¡ç®—è¯æ±‡é‡å åº¦
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union)
    
    def _calculate_importance_score(
        self,
        user_text: str,
        ai_response: str,
        mood_tag: str,
        touched: bool,
    ) -> float:
        """è®¡ç®—è®°å¿†çš„é‡è¦æ€§è¯„åˆ†
        
        Parameters
        ----------
        user_text: str
            ç”¨æˆ·è¾“å…¥
        ai_response: str
            AIå›å¤
        mood_tag: str
            æƒ…ç»ªæ ‡ç­¾
        touched: bool
            æ˜¯å¦è¢«è§¦æ‘¸
        
        Returns
        -------
        float
            é‡è¦æ€§è¯„åˆ†ï¼ˆ0-1ï¼‰
        """
        score = 0.5  # åŸºç¡€åˆ†æ•°
        
        # 1. æƒ…ç»ªå¼ºåº¦
        emotion_scores = {
            "happy": 0.8,
            "excited": 0.9,
            "angry": 0.7,
            "sad": 0.6,
            "surprised": 0.8,
            "neutral": 0.5,
        }
        score += emotion_scores.get(mood_tag, 0.5) * 0.3
        
        # 2. è§¦æ‘¸äº¤äº’
        if touched:
            score += 0.2
        
        # 3. æ–‡æœ¬é•¿åº¦ï¼ˆæ›´é•¿çš„å¯¹è¯å¯èƒ½æ›´é‡è¦ï¼‰
        text_length = len(user_text) + len(ai_response)
        score += min(text_length / 1000, 0.2)  # æœ€å¤šåŠ 0.2åˆ†
        
        # 4. ç‰¹æ®Šå…³é”®è¯
        important_keywords = ["å–œæ¬¢", "è®¨åŒ", "é‡è¦", "è®°ä½", "love", "hate", "important"]
        for keyword in important_keywords:
            if keyword in user_text.lower() or keyword in ai_response.lower():
                score += 0.1
                break
        
        return min(score, 1.0)  # ç¡®ä¿ä¸è¶…è¿‡1.0
    
    def _generate_memory_summary(
        self, memories: List[Dict[str, Any]]
    ) -> str:
        """ç”Ÿæˆè®°å¿†æ‘˜è¦
        
        Parameters
        ----------
        memories: List[Dict[str, Any]]
            è®°å¿†åˆ—è¡¨
        
        Returns
        -------
        str
            è®°å¿†æ‘˜è¦
        """
        if not memories:
            return ""
        
        summary_parts = []
        
        # é€‰æ‹©æœ€é‡è¦çš„è®°å¿†ç”Ÿæˆæ‘˜è¦
        important_memories = sorted(
            memories, 
            key=lambda x: x.get("importance_score", 0), 
            reverse=True
        )[:3]
        
        for i, memory in enumerate(important_memories):
            user_text = memory["user_text"]
            ai_response = memory["ai_response"]
            mood = memory.get("mood_tag", "neutral")
            
            summary_part = f"ç”¨æˆ·è¯´'{user_text}'æ—¶ï¼Œæˆ‘å›å¤'{ai_response}'"
            if mood != "neutral":
                summary_part += f"ï¼Œå½“æ—¶æƒ…ç»ªæ˜¯{mood}"
            
            summary_parts.append(summary_part)
        
        return "ã€‚".join(summary_parts)
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–è®°å¿†ç»Ÿè®¡ä¿¡æ¯
        
        Returns
        -------
        Dict[str, Any]
            è®°å¿†ç»Ÿè®¡ä¿¡æ¯
        """
        return {
            "robot_id": self.robot_id,
            "session_count": len(self.session_memory),
            "session_limit": self.session_limit,
            "context_counter": self.context_counter,
            "semantic_memory_available": self.semantic_memory is not None,
        }
    
    def clear_session_memory(self) -> int:
        """æ¸…ç©ºä¼šè¯è®°å¿†
        
        Returns
        -------
        int
            æ¸…é™¤çš„è®°å½•æ•°é‡
        """
        count = len(self.session_memory)
        self.session_memory.clear()
        self.context_counter = 0
        
        logger.info(f"ğŸ—‘ï¸ ä¼šè¯è®°å¿†å·²æ¸…ç©º - æ¸…é™¤è®°å½•æ•°: {count}")
        
        return count 